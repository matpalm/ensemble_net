{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data as d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0904 19:51:01.526964 139795642832704 ag_logging.py:146] AutoGraph could not transform <function dataset.<locals>.to_float at 0x7f23900d3950> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function dataset.<locals>.to_float at 0x7f23900d3950> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "imgs (4, 64, 64, 3)\n",
      "[[[0.09803922 0.16470589 0.26666668]\n",
      "  [0.10196079 0.16862746 0.27058825]\n",
      "  [0.09803922 0.16470589 0.26666668]\n",
      "  ...\n",
      "  [0.09803922 0.16470589 0.27450982]\n",
      "  [0.09411765 0.17254902 0.2784314 ]\n",
      "  [0.09019608 0.16862746 0.27450982]]\n",
      "\n",
      " [[0.09803922 0.16470589 0.26666668]\n",
      "  [0.10196079 0.16862746 0.27058825]\n",
      "  [0.09803922 0.16470589 0.26666668]\n",
      "  ...\n",
      "  [0.09803922 0.16470589 0.27450982]\n",
      "  [0.09019608 0.16862746 0.27450982]\n",
      "  [0.09411765 0.17254902 0.2784314 ]]\n",
      "\n",
      " [[0.09411765 0.17254902 0.27058825]\n",
      "  [0.09019608 0.16862746 0.26666668]\n",
      "  [0.09411765 0.16078432 0.27058825]\n",
      "  ...\n",
      "  [0.09411765 0.17254902 0.27058825]\n",
      "  [0.09411765 0.16078432 0.27058825]\n",
      "  [0.09803922 0.16470589 0.27450982]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.09019608 0.16862746 0.26666668]\n",
      "  [0.09019608 0.16862746 0.26666668]\n",
      "  [0.10196079 0.16862746 0.2784314 ]\n",
      "  ...\n",
      "  [0.09019608 0.16862746 0.26666668]\n",
      "  [0.09803922 0.1764706  0.27058825]\n",
      "  [0.1254902  0.21176471 0.29411766]]\n",
      "\n",
      " [[0.09411765 0.17254902 0.27058825]\n",
      "  [0.09019608 0.16862746 0.26666668]\n",
      "  [0.09019608 0.16862746 0.26666668]\n",
      "  ...\n",
      "  [0.09803922 0.1764706  0.28235295]\n",
      "  [0.10980392 0.1882353  0.28235295]\n",
      "  [0.1254902  0.21176471 0.3019608 ]]\n",
      "\n",
      " [[0.09019608 0.16862746 0.26666668]\n",
      "  [0.09019608 0.16862746 0.26666668]\n",
      "  [0.09019608 0.16862746 0.26666668]\n",
      "  ...\n",
      "  [0.09803922 0.1764706  0.28235295]\n",
      "  [0.11764706 0.19607843 0.29411766]\n",
      "  [0.12941177 0.21568628 0.30588236]]]\n",
      "labels [9 1 8 3]\n"
     ]
    }
   ],
   "source": [
    "ds = d.dataset('test', batch_size=4)\n",
    "for imgs, labels in ds:\n",
    "    print(\"imgs\", imgs.shape)\n",
    "    print(imgs[0])\n",
    "    print(\"labels\", labels)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import random, lax, vmap\n",
    "from jax.nn.initializers import glorot_normal, he_normal\n",
    "from jax.nn.functions import gelu\n",
    "from functools import partial\n",
    "import objax\n",
    "from objax.variable import TrainVar\n",
    "\n",
    "\n",
    "def _conv_layer(stride, activation, inp, kernel, bias):\n",
    "    no_dilation = (1, 1)\n",
    "    some_height_width = 10  # values don't matter; just shape of input\n",
    "    input_shape = (1, some_height_width, some_height_width, 3)\n",
    "    kernel_shape = (3, 3, 1, 1)\n",
    "    input_kernel_output = ('NHWC', 'HWIO', 'NHWC')\n",
    "    conv_dimension_numbers = lax.conv_dimension_numbers(input_shape,\n",
    "                                                        kernel_shape,\n",
    "                                                        input_kernel_output)\n",
    "    block = lax.conv_general_dilated(inp, kernel, (stride, stride),\n",
    "                                     'VALID', no_dilation, no_dilation,\n",
    "                                     conv_dimension_numbers)\n",
    "    if bias is not None:\n",
    "        block += bias\n",
    "    if activation:\n",
    "        block = activation(block)\n",
    "    return block\n",
    "\n",
    "def _dense_layer(inp, activation, kernel, bias):\n",
    "    block = jnp.dot(inp, kernel) + bias\n",
    "    if activation:\n",
    "        block = activation(block)\n",
    "    return block\n",
    "\n",
    "# def _conv_block_without_bias(stride, with_non_linearity, inp, kernel):\n",
    "#     # the need for this method feels a bit clunky :/ is there a better\n",
    "#     # way to vmap with the None?\n",
    "#     return _conv_block(stride, with_non_linearity, inp, kernel, None)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NonEnsembleNet(objax.Module):\n",
    "\n",
    "    def __init__(self, num_classes, dense_kernel_size=32, seed=0):\n",
    "\n",
    "        key = random.PRNGKey(seed)\n",
    "        subkeys = random.split(key, 8)\n",
    "\n",
    "        # conv stack kernels and biases\n",
    "        self.conv_kernels = objax.ModuleList()\n",
    "        self.conv_biases = objax.ModuleList()\n",
    "        input_channels = 3\n",
    "        for i, output_channels in enumerate([32, 64, 64, 64]):\n",
    "            self.conv_kernels.append(TrainVar(he_normal()(subkeys[i], (3, 3, input_channels,\n",
    "                                                                       output_channels))))\n",
    "            self.conv_biases.append(TrainVar(jnp.zeros((output_channels))))\n",
    "            input_channels = output_channels\n",
    "\n",
    "        # dense layer kernel and bias\n",
    "        self.dense_kernel = TrainVar(he_normal()(subkeys[6], (output_channels, dense_kernel_size)))\n",
    "        self.dense_bias = TrainVar(jnp.zeros((dense_kernel_size)))\n",
    "\n",
    "        # classifier layer kernel and bias\n",
    "        self.logits_kernel = TrainVar(glorot_normal()(subkeys[6], (dense_kernel_size, num_classes)))\n",
    "        self.logits_bias = TrainVar(jnp.zeros((num_classes)))\n",
    "\n",
    "    def logits(self, inp):        \n",
    "        # conv stack -> (B, 3, 3, 64)\n",
    "        y = inp\n",
    "        for kernel, bias in zip(self.conv_kernels, self.conv_biases):\n",
    "            y = _conv_layer(2, gelu, y, kernel.value, bias.value)\n",
    "            \n",
    "        # global spatial pooling -> (B, 64)\n",
    "        y = jnp.mean(y, axis=(1, 2))\n",
    "            \n",
    "        # dense layer with non linearity -> (B, 32)\n",
    "        y = _dense_layer(y, gelu, self.dense_kernel.value, self.dense_bias.value)\n",
    "        \n",
    "        # dense layer with no activation to number classes -> (B, num_classes)\n",
    "        logits = _dense_layer(y, None, self.logits_kernel.value, self.logits_bias.value)\n",
    "        \n",
    "        return logits\n",
    "        \n",
    "    def predict(self, inp):\n",
    "        return jax.nn.softmax(self.logits(inp))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.059      -0.036      -0.083       0.037       0.043       0.005\n",
      "  -0.089       0.038       0.006       0.051     ]\n",
      " [-0.074      -0.045      -0.11100001  0.053       0.054      -0.001\n",
      "  -0.109       0.047      -0.004       0.064     ]\n",
      " [-0.266      -0.18900001 -0.208       0.17300001  0.141      -0.109\n",
      "  -0.314       0.125       0.041       0.09900001]\n",
      " [-0.08800001 -0.054      -0.11800001  0.063       0.062      -0.015\n",
      "  -0.13900001  0.057      -0.002       0.068     ]]\n",
      "[[0.09500001 0.097      0.093      0.105      0.105      0.101\n",
      "  0.09200001 0.105      0.101      0.10600001]\n",
      " [0.094      0.097      0.09       0.10700001 0.10700001 0.101\n",
      "  0.09100001 0.10600001 0.101      0.108     ]\n",
      " [0.079      0.086      0.08400001 0.123      0.119      0.093\n",
      "  0.07600001 0.11700001 0.108      0.11400001]\n",
      " [0.093      0.096      0.09       0.108      0.108      0.1\n",
      "  0.08800001 0.10700001 0.101      0.109     ]]\n"
     ]
    }
   ],
   "source": [
    "net = NonEnsembleNet(num_classes=10)\n",
    "print(jnp.around(net.logits(imgs), 3))\n",
    "print(jnp.around(net.predict(imgs), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 64, 64, 3)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy(imgs, labels):\n",
    "    logits = net.logits(imgs)\n",
    "    return jnp.mean(objax.functional.loss.cross_entropy_logits_sparse(logits, labels))\n",
    "\n",
    "gradient_loss = objax.GradValues(cross_entropy, net.vars())\n",
    "optimiser = objax.optimizer.Adam(net.vars())\n",
    "lr = 1e-3\n",
    "\n",
    "# create a jitted training step\n",
    "def train_step(imgs, labels):\n",
    "    grads, loss = gradient_loss(imgs, labels)\n",
    "    optimiser(lr, grads)\n",
    "    return loss\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DeviceArray(1.2861435, dtype=float32)]\n",
      "[DeviceArray(1.175744, dtype=float32)]\n",
      "[DeviceArray(1.0832641, dtype=float32)]\n",
      "[DeviceArray(1.0269818, dtype=float32)]\n",
      "[DeviceArray(0.9848052, dtype=float32)]\n",
      "[DeviceArray(0.93037367, dtype=float32)]\n",
      "[DeviceArray(0.8638202, dtype=float32)]\n",
      "[DeviceArray(0.8097404, dtype=float32)]\n",
      "[DeviceArray(0.77046627, dtype=float32)]\n",
      "[DeviceArray(0.70041114, dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    print(train_step(imgs, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([[0.        , 0.38      , 0.        , 0.17      , 0.01      ,\n",
       "              0.        , 0.        , 0.02      , 0.01      , 0.41      ],\n",
       "             [0.        , 0.35999998, 0.        , 0.31      , 0.        ,\n",
       "              0.        , 0.        , 0.01      , 0.02      , 0.29      ],\n",
       "             [0.        , 0.        , 0.        , 0.02      , 0.        ,\n",
       "              0.        , 0.        , 0.        , 0.97999996, 0.        ],\n",
       "             [0.        , 0.22      , 0.        , 0.53      , 0.        ,\n",
       "              0.        , 0.        , 0.        , 0.05      , 0.19      ]],            dtype=float32)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.around(net.predict(imgs), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 1, 8, 3])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
